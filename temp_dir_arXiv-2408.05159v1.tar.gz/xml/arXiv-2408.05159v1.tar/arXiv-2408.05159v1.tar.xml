<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE std SYSTEM 'classes.dtd'>
<!-- Translated from latex by tralics 2.14.4, date: 2024/08/26-->
<std>
<p>rm</p>
<p>8.5in 11in</p>
<p>ruledlabelfont=normalfont,labelsep=colon,strut=off 
ruled
listingtblst
listingListing

/TemplateVersion (2025.1)</p>
<p>0</p>
<p><hi rend='sup'>1</hi>Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University, China</p>
<p noindent='true'><hi rend='sup'>2</hi>Skywork AI, Singapore</p>
<p noindent='true'>zhang_zi_yue@foxmail.com, linmb001@outlook.com, shuicheng.yan@kunlun-inc.com, rrji@xmu.edu.cn</p>
<maketitle><title>EasyInv: Toward Fast and Better DDIM Inversion</title><author>
Ziyue Zhang<hi rend='sup'>1</hi>,
Mingbao Lin<hi rend='sup'>2</hi>,
Shuicheng Yan<hi rend='sup'>2</hi>,
Rongrong Ji<hi rend='sup'>1</hi>
</author><date>2024/08/26 16:09:32</date></maketitle><p>This paper introduces EasyInv, an easy yet novel approach that significantly advances the field of DDIM Inversion by addressing the inherent inefficiencies and performance limitations of traditional iterative optimization methods.
At the core of our EasyInv is a refined strategy for approximating inversion noise, which is pivotal for enhancing the accuracy and reliability of the inversion process.
By prioritizing the initial latent state, which encapsulates rich information about the original images, EasyInv steers clear of the iterative refinement of noise items.
Instead, we introduce a methodical aggregation of the latent state from the preceding time step with the current state, effectively increasing the influence of the initial latent state and mitigating the impact of noise.
We illustrate that EasyInv is capable of delivering results that are either on par with or exceed those of the conventional DDIM Inversion approach, especially under conditions where the model's precision is limited or computational resources are scarce. Concurrently, our EasyInv offers an approximate threefold enhancement regarding inference efficiency over off-the-shelf iterative optimization techniques.</p>
<div0 id-text='1' id='cid1'><head>Introduction</head>
<p>Diffusion models have become a major focus of research in recent years, mostly renowned for their ability to generate high-quality images that closely match given prompts. Among the many diffusion models introduced in the community, Stable Diffusion (SD) <cit><ref target='bid0'/></cit> stands out as one of the most widely utilized in scientific research, largely due to its open-source nature. Another contemporary diffusion model gaining popularity is DALL-E 3 <cit><ref target='bid1'/></cit>, which offers users access to its API and the ability to interact with it through platforms like ChatGPT <cit><ref target='bid2'/></cit>.
These models have significantly transformed the visual arts industry and have attracted substantial attention from the research community.</p>
<p>While renowned generative diffusion models have made significant strides, a prevalent limitation is their reliance on textual prompts for input.
This approach becomes restrictive when users seek to iteratively refine an image, as the sole reliance on prompts hinders flexibility.
Although solutions such as ObjectAdd <cit><ref target='bid3'/></cit> and P2P <cit><ref target='bid4'/></cit> have been proposed to address image editing challenges, they are still confined to the realm of prompted image manipulation.
Given that diffusion models generate images from noise inputs, a potential breakthrough lies in identifying the corresponding noise for any given image.
This would enable the diffusion model to initiate the generation process from a known starting point, thereby allowing for precise control over the final output.
The recent innovation of DDIM Inversion <cit><ref target='bid5'/></cit> aims to overcome this challenge by reversing the denoising process to introduce noise.
This technique effectively retrieves the initial noise configuration after a series of reference steps, thereby preserving the integrity of the original image while affording the user the ability to manipulate the output by adjusting the denoising parameters.
With DDIM inversion, the generative process becomes more adaptable, facilitating the creation and subsequent editing of images with greater precision and control.
For example, the MasaCtrl method <cit><ref target='bid6'/></cit> first transforms a real image into a noise representation and then identifies the arrangement of objects during the denoising phase.
Portrait Diffusion<cit><ref target='bid7'/></cit> simultaneously inverts both the source and target images. Subsequently, it merges their respective <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>Q</mi></math><texmath>Q</texmath></formula>, <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>K</mi></math><texmath>K</texmath></formula> and <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>V</mi></math><texmath>V</texmath></formula> values for mixups.</p>
<figure width='418.45818pt' file='visual_hat_result_together_cut' extension='pdf' id-text='1' id='uid1'><head>Performance comparison of inversion methods including vanilla DDIM Inversion <cit><ref target='bid5'/></cit>, Fixed-Point Iteration <cit><ref target='bid8'/></cit>, ReNoise <cit><ref target='bid9'/></cit> and our EasyInv. The proposed EasyInv performs well upon different diffusion models of SD-V1-4 and SD-XL.</head>
</figure>
<p>Considering the reliance on inversion techniques to preserve the integrity of the input image, the quality of the inversion process is paramount, as it profoundly influences subsequent tasks.
As depicted in Figure <ref target='uid1'/>(a), the performance of DDIM Inversion has been found to be less than satisfactory due to the discrepancy between the noise estimated during the inversion process and the noise expected in the sampling process.
Consequently, numerous studies have been conducted to enhance its efficacy.
In Null-Text inversion <cit><ref target='bid10'/></cit>, researchers observed that using a null prompt as input, the diffusion model could generate optimal results during inversion, suggesting that improvements to inversion might be better achieved in the reconstruction branch.
Ju <hi rend='it'>et al</hi>.'s work <cit><ref target='bid11'/></cit> exemplifies this approach by calculating the distance between latents at the current step and the previous step.
PTI <cit><ref target='bid12'/></cit> opts to update the conditional vector in each step to guide the reconstruction branch for improving consistency.
ReNoise <cit><ref target='bid9'/></cit> focuses on refining the inversion process itself. This method iteratively adds and then denoises noise at each time step, using the denoised noise as input for the subsequent iteration. However, as shown in Figure <ref target='uid1'/>(b), it can result in a black image output when dealing with certain special inputs, which will be discussed in detail in Sec. <ref target='cid4'/>.
Pan <hi rend='it'>et al.</hi> <cit><ref target='bid8'/></cit>, while maintaining the iterative updating process, also amalgamated noise from previous steps with the current step's noise. However, this method's performance is limited in less effective models as displayed in Figure<ref target='uid1'/>(c). For instance, it performs well in SD-XL <cit><ref target='bid13'/></cit> but fails to yield proper results in SD-V1-4 <cit><ref target='bid0'/></cit>. We attribute this to their method's sole focus on optimizing noise; when the noise is highly inaccurate, such simple optimization strategies encounter difficulties. Additionally, the iterative updating of noise is time-consuming, as Pan <hi rend='it'>et al.</hi>'s method requires multiple model inferences per time step.</p>
<p>In this paper, we conduct an in-depth analysis and recognize that the foundation of any inversion process is the initial latent state derived from a real image. Errors introduced at each step of the inversion process can accumulate, leading to a suboptimal reconstruction. Current methodologies, which focus on optimizing the transition between successive steps, may not be adequate to address this issue holistically. To tackle this, we propose a novel approach that considers the inversion process as a whole, underscoring the significance of the initial latent state throughout the process. Our approach, named EasyInv, incorporates a straightforward mechanism to periodically reinforce the influence of the initial latent state during the inversion. This is realized by blending the current latent state with the previous one at strategically selected intervals, thereby increasing the weight of the initial latent state and diminishing the noise's impact. As a result, EasyInv ensures a reconstructed version that remains closer to the original image, as illustrated in Figure <ref target='uid1'/>(d). Furthermore, by building upon the traditional DDIM Inversion framework <cit><ref target='bid5'/></cit>, EasyInv does not depend on iterative optimization between adjacent steps, thus enhancing computational efficiency. In Figure <ref target='uid2'/>, we present a visualization of the latent states at the midpoint of the total denoising steps for various inversion methods. It is evident that the outcomes of our EasyInv are more closely aligned with the original image compared to all other methods, demonstrating that EasyInv achieves faster convergence.</p>
<figure width='418.45818pt' file='visual_hat_noise_together_cut' extension='pdf' id-text='2' id='uid2' place='!t'><head>Visualization of the latent states midway through all denoising steps for various inversion methods. Our EasyInv shows its enhanced convergence by closely approximating the original image.</head>
</figure>
</div0>
<div0 id-text='2' id='cid2'><head>Related Works</head>
<p><hi rend='bold'>Diffusion Model</hi>.
In recent years, there has been significant progress in the field of generative models, with diffusion models emerging as a particularly popular approach.
The seminal denoising diffusion probabilistic models (DDPM) <cit><ref target='bid14'/></cit> introduced a practical framework for image generation based on the diffusion process.
This method stands out from its predecessors, such as generative adversarial networks (GANs), due to its iterative nature.
During the data preparation phase, Gaussian noise is incrementally added to a real image until it transitions into a state that is indistinguishable from raw Gaussian noise.
Subsequently, a model can be trained to predict the noise added at each step, enabling users to input any Gaussian noise and obtain a high-quality image as a result.
Ho <hi rend='it'>et al</hi>. <cit><ref target='bid14'/></cit> provided a robust theoretical foundation for their model, which has facilitated further advancements.
Generative process in DDPM is both time-consuming and inherently stochastic due to the random noise introduced at each step. To address these limitations, the denoising diffusion implicit models (DDIM) were developed <cit><ref target='bid15'/></cit>.
By reformulating DDPM, DDIM has successfully reduced the amount of random noise added at each step. This reformulation results in a more deterministic denoising process. Furthermore, the absence of random noise allows for the aggregation of several denoising steps, thereby significantly reducing the overall computation time required to generate an image.</p>
<p><hi rend='bold'>Image Inversion</hi>.
Converting a real image into noise is a pivotal first step in the realm of real image editing using diffusion models.
The precision of this process has a profound impact in the final edit, with the critical element being the accurate identification of the noise added at each step.
Couairon <hi rend='it'>et al</hi>. <cit><ref target='bid5'/></cit> ingeniously swapped the roles of independent and implicit variables within the denoising function of the DDIM model, enabling it to predict the noise that should be introduced to the current latents.
However, it is essential to recognize that the denoising step in a diffusion model is inherently an approximation, and when this approximation is utilized inversely, discrepancies between the model's output and the actual noise value are likely to be exacerbated.
To address this issue, ReNoise <cit><ref target='bid9'/></cit> iterates through each noising step multiple times. For each inversion step, they employ an iterative approach to add and subsequently reduce noise, with the noise reduced in the final iteration being carried forward to the subsequent iteration.
Pan <hi rend='it'>et al.</hi> <cit><ref target='bid8'/></cit> offered a theoretical underpinning to the ReNoise method. Iterative optimization from ReNoise is classified under the umbrella of fixed-point iteration methods. Building upon Anderson's seminal work <cit><ref target='bid16'/></cit>, Pan <hi rend='it'>et al</hi>. have advanced the field by proposing their novel method for optimizing noise during the inversion process.</p>
</div0>
<div0 id-text='3' id='cid3'><head>Methodology</head>
<div1 id-text='3.1' id='uid3'><head>Preliminaries</head>
<div2 id-text='3.1.1' id='uid4'><head>DDIM Inversion</head>
<p>Let <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mi>T</mi> </msub></math><texmath>\mathbf {z}_T</texmath></formula> denote a noise tensor with <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msub><mi>&#x1D433;</mi> <mi>T</mi> </msub><mo>&#x0223C;</mo><mi>&#x2110;</mi><mrow><mo>(</mo><mn>0</mn><mo>,</mo><mi>&#x1D408;</mi><mo>)</mo></mrow></mrow></math><texmath>\mathbf {z}_T \sim \mathcal {I}(0, \mathbf {I})</texmath></formula>. The DDIM <cit><ref target='bid5'/></cit> leverages a pre-trained neural network <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub></math><texmath>\varepsilon _{\theta }</texmath></formula> to perform <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>T</mi></math><texmath>T</texmath></formula> denoising diffusion steps. Each step aims to estimate the underlying noise and subsequently restore a less noisy version of the tensor, <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub></math><texmath>\mathbf {z}_{t-1}</texmath></formula>, from its noisy counterpart <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub></math><texmath>\mathbf {z}_t</texmath></formula> as:
<hi rend='small'/></p>
<formula id-text='1' id='uid5' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msub><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub><mo>=</mo><msqrt><mfrac><msub><mi>&#x3B1;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub> <msub><mi>&#x3B1;</mi> <mi>t</mi> </msub></mfrac></msqrt><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub><mo>+</mo><mfenced separators='' open='(' close=')'><msqrt><mrow><mfrac><mn>1</mn> <msub><mi>&#x3B1;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub></mfrac><mo>-</mo><mn>1</mn></mrow></msqrt> <mo>-</mo> <msqrt><mrow><mfrac><mn>1</mn> <msub><mi>&#x3B1;</mi> <mi>t</mi> </msub></mfrac><mo>-</mo><mn>1</mn></mrow></msqrt></mfenced><mo>&#xB7;</mo><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub> <mo>,</mo> <mi>t</mi> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced><mo>,</mo></mrow></math><texmath>

\mathbf {z}_{t-1} = \sqrt{\frac{\alpha _{t-1}}{\alpha _t}}\mathbf {z}_t + \Bigg (\sqrt{\frac{1}{\alpha _{t-1}} - 1} - \sqrt{\frac{1}{\alpha _t} - 1} \Bigg )\cdot \varepsilon _{\theta }\big (\mathbf {z}_t,t,\tau _{\theta }(y)\big ),
</texmath></formula>
<p noindent='true'><hi rend='small'/>
where <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>t</mi><mo>=</mo><mi>T</mi><mo>&#x02192;</mo><mn>1</mn></mrow></math><texmath> t = T \rightarrow 1</texmath></formula>, and <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mrow><mo>&#x0007B;</mo><msub><mi>&#x3B1;</mi> <mi>t</mi> </msub><mo>&#x0007D;</mo></mrow> <mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow> <mi>T</mi> </msubsup></math><texmath> \lbrace \alpha _t\rbrace _{t=1}^T </texmath></formula> constitutes a prescribed variances set that guides the diffusion process. Furthermore, <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub></math><texmath> \tau _{\theta } </texmath></formula> serves as an intermediate representation that encapsulates the textual condition <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>y</mi></math><texmath> y </texmath></formula>. For the convenience of following sections, we denote:</p>
<formula id-text='2' id='uid6' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>d</mi><mrow><mo>(</mo><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub><mo>)</mo></mrow><mo>=</mo><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub> <mo>,</mo> <mi>t</mi> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced><mo>.</mo></mrow></math><texmath>
d(\mathbf {z}_t) = \varepsilon _{\theta }\big (\mathbf {z}_t,t,\tau _{\theta }(y)\big ).
</texmath></formula>
<p>Re-evaluating Eq. (<ref target='uid5'/>), we derive DDIM Inversion process <cit><ref target='bid5'/></cit> as presented in Eq.(<ref target='uid7'/>). In this reformulation, we relocate an approximate <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_t</texmath></formula> to the left-hand side, resulting in the following expression:
<hi rend='small'/></p>
<formula id-text='3' id='uid7' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mtable displaystyle='true'><mtr><mtd columnalign='right'><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup></mtd><mtd columnalign='left'><mrow><mo>=</mo><mi>g</mi><mfenced separators='' open='(' close=')'><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup> <mo>,</mo> <mi>t</mi> <mo>-</mo> <mn>1</mn> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced></mfenced></mrow></mtd></mtr><mtr><mtd/><mtd columnalign='left'><mrow><mo>=</mo><msqrt><mfrac><msub><mi>&#x3B1;</mi> <mi>t</mi> </msub> <msub><mi>&#x3B1;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub></mfrac></msqrt><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup><mo>-</mo></mrow></mtd></mtr><mtr><mtd/><mtd columnalign='left'><mrow><msqrt><mfrac><msub><mi>&#x3B1;</mi> <mi>t</mi> </msub> <msub><mi>&#x3B1;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub></mfrac></msqrt><mfenced separators='' open='(' close=')'><msqrt><mrow><mfrac><mn>1</mn> <msub><mi>&#x3B1;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub></mfrac><mo>-</mo><mn>1</mn></mrow></msqrt> <mo>-</mo> <msqrt><mrow><mfrac><mn>1</mn> <msub><mi>&#x3B1;</mi> <mi>t</mi> </msub></mfrac><mo>-</mo><mn>1</mn></mrow></msqrt></mfenced><mo>&#xB7;</mo><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup> <mo>,</mo> <mi>t</mi> <mo>-</mo> <mn>1</mn> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced><mo>,</mo></mrow></mtd></mtr></mtable></math><texmath>

\begin{split}
\mathbf {z}^*_t &amp;= g\left(\varepsilon _{\theta }\big (\mathbf {z}^*_{t-1},t-1,\tau _{\theta }(y)\big )\right) \\&amp;= \sqrt{\frac{\alpha _{t}}{\alpha _{t-1}}}\mathbf {z}^*_{t-1} -\\&amp; \sqrt{\frac{\alpha _{t}}{\alpha _{t-1}}}\Bigg (\sqrt{\frac{1}{\alpha _{t-1}} - 1} - \sqrt{\frac{1}{\alpha _t} - 1} \Bigg ) \cdot \varepsilon _{\theta }\big (\mathbf {z}^*_{t-1},t-1,\tau _{\theta }(y)\big ),
\end{split}
</texmath></formula>
<p noindent='true'><hi rend='small'/></p>
<p><hi rend='bold'>Review</hi>. Given an image <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msup><mi>&#x1D408;</mi> <mo>*</mo> </msup></math><texmath>\mathbf {I}^*</texmath></formula>, after encoding it into the latent <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mn>0</mn> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_0</texmath></formula>, we initiate <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>T</mi></math><texmath>T</texmath></formula> inversion steps using Eq. (<ref target='uid7'/>) to obtain the noise <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mi>T</mi> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_T</texmath></formula>. Starting with <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msub><mi>&#x1D433;</mi> <mi>T</mi> </msub><mo>=</mo><msubsup><mi>&#x1D433;</mi> <mi>T</mi> <mo>*</mo> </msubsup></mrow></math><texmath>\mathbf {z}_T = \mathbf {z}^*_T</texmath></formula>, we proceed with a denoising process in Eq. (<ref target='uid5'/>) to infer an approximate reconstruction <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mn>0</mn> </msub></math><texmath>\mathbf {z}_0</texmath></formula> that resembles the original latent <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mn>0</mn> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_0</texmath></formula>. The primary source of error in this reconstruction arises from the difference between the noise predicted during the inversion process <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup> <mo>,</mo> <mi>t</mi> <mo>-</mo> <mn>1</mn> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced></mrow></math><texmath>\varepsilon _{\theta }\big (\mathbf {z}^*_{t-1}, t-1, \tau _{\theta }(y)\big )</texmath></formula> and the noise expected in the sampling process, <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub> <mo>,</mo> <mi>t</mi> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced></mrow></math><texmath>\varepsilon _{\theta }\big (\mathbf {z}_t, t, \tau _{\theta }(y)\big )</texmath></formula>, denoted as <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x3B5;</mi> <mi>t</mi> </msub></math><texmath>\varepsilon _t</texmath></formula>, at each iterative step. This discrepancy originates from an imprecise approximation of the time step from <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>t</mi></math><texmath>t</texmath></formula> to <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></math><texmath>t-1</texmath></formula>. Therefore, reducing the discrepancy between the predicted noises at each step is crucial for achieving an accurate reconstruction, which is essential for the success of subsequent image editing tasks. For simplicity in the following expressions, we define:</p>
<formula id-text='4' id='uid8' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x3B5;</mi> <mrow><mi>t</mi></mrow> <mo>*</mo> </msubsup><mo>=</mo><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup> <mo>,</mo> <mi>t</mi> <mo>-</mo> <mn>1</mn> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced><mo>,</mo><mspace width='2.em'/><msub><mi>&#x3B5;</mi> <mi>t</mi> </msub><mo>=</mo><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub> <mo>,</mo> <mi>t</mi> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced><mo>.</mo></mrow></math><texmath>
\varepsilon _{t}^* = \varepsilon _{\theta }\big (\mathbf {z}^*_{t-1},t-1,\tau _{\theta }(y)\big ), \qquad \varepsilon _t = \varepsilon _{\theta }\big (\mathbf {z}_t,t,\tau _{\theta }(y)\big ).
</texmath></formula>
</div2></div1>
<div1 id-text='3.2' id='uid9'><head>Fixed-Point Iteration</head>
<p>The vanilla DDIM Inversion method, as discussed, involves an approximation that is not entirely precise for <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon _t^*</texmath></formula>. To address this, researchers have sought to refine a more accurate approximation of <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon _t^*</texmath></formula>, thereby ensuring that the desired conditions are optimally met. This refinement process aims to enhance the precision of the method, leading to more reliable results in the context of the application:</p>
<formula id-text='5' id='uid10' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>=</mo><msub><mi>&#x3B5;</mi> <mi>t</mi> </msub><mo>.</mo></mrow></math><texmath>
\varepsilon _t^* = \varepsilon _t.
</texmath></formula>
<p>For clarity, let's first restate Eq. (<ref target='uid7'/>) as follows:</p>
<formula id-text='6' id='uid11' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>=</mo><mi>g</mi><mrow><mo>(</mo><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow><mo>,</mo></mrow></math><texmath>
\mathbf {z}^*_t = g(\varepsilon _t^*),
</texmath></formula>
<p noindent='true'>which represents the introduction of adding noise to the latent state <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{t-1}</texmath></formula>. Under the assumption of Eq. (<ref target='uid10'/>), it should be the case that:</p>
<formula id-text='7' id='uid12' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub><mo>=</mo><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>.</mo></mrow></math><texmath>
\mathbf {z}_t = \mathbf {z}_t^*.
</texmath></formula>
<p>Subsequently, by employing the noise estimation function from Eq. (<ref target='uid6'/>), we obtain:</p>
<formula id-text='8' id='uid13' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>d</mi><mo>(</mo><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub><mrow><mo>)</mo><mo>=</mo><mi>d</mi></mrow><mfenced separators='' open='(' close=')'><mi>g</mi> <mo>(</mo> <msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup> <mo>)</mo></mfenced><mo>.</mo></mrow></math><texmath>
d\big (\mathbf {z}_t) = d\big (g(\varepsilon _t^*)\big ).
</texmath></formula>
<p>Given that <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>d</mi><mrow><mo>(</mo><msub><mi>&#x1D433;</mi> <mi>t</mi> </msub><mo>)</mo></mrow><mo>=</mo><msub><mi>&#x3B5;</mi> <mi>t</mi> </msub></mrow></math><texmath>d(\mathbf {z}_t) = \varepsilon _{t}</texmath></formula> and considering Eq. (<ref target='uid10'/>), we can deduce that:</p>
<formula id-text='9' id='uid14' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x3B5;</mi> <mrow><mi>t</mi></mrow> <mo>*</mo> </msubsup><mo>=</mo><mi>d</mi><mfenced separators='' open='(' close=')'><mi>g</mi> <mo>(</mo> <msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup> <mo>)</mo></mfenced><mo>.</mo></mrow></math><texmath>
\varepsilon _{t}^* = d\big (g(\varepsilon _t^*)\big ).
</texmath></formula>
<p>This formulation presents a fixed-point problem, which pertains to a value that remains unchanged under a specific transformation <cit><ref target='bid17'/></cit>. In the context of functions, a fixed point is an element that is invariant under the application of the function. In this paper, we seek a <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon ^*_t</texmath></formula> that, when transformed by <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>g</mi></math><texmath>g</texmath></formula> and followed by <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>d</mi></math><texmath>d</texmath></formula>, can map back to itself, signifying an optimal solution as per Eq. (<ref target='uid10'/>).</p>
<p>Fixed-point iteration is a computational technique designed to identify the fixed points of a function. It functions through an iterative process, as delineated below:</p>
<formula id-text='10' id='uid15' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msup><mrow><mo>(</mo><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mi>n</mi> </msup><mo>=</mo><mi>d</mi><mfenced separators='' open='(' close=')'><mi>g</mi> <msup><mrow><mo>(</mo><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow> </msup></mfenced><mo>,</mo></mrow></math><texmath>
(\varepsilon ^*_{t})^n = d\big (g(\varepsilon ^*_{t})^{n-1}\big ),
</texmath></formula>
<p noindent='true'>where <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>n</mi></math><texmath>n</texmath></formula> denotes the iteration count. This iterative process can be enhanced through acceleration techniques such as Anderson acceleration  <cit><ref target='bid16'/></cit>.
However, calculating a complex <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon ^*_{t}</texmath></formula> can be quite onerous. An empirical acceleration method proposed <cit><ref target='bid8'/></cit> introduces a refinement for <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon _t^*</texmath></formula> by setting: <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mfenced separators='' open='(' close=')'><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup> <mrow><msup><mo>)</mo> <mi>n</mi> </msup><mo>=</mo><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mo>(</mo></mrow> <msup><mrow><mo>(</mo><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mi>n</mi> </msup> <mo>,</mo> <mi>t</mi> <mo>-</mo> <mn>1</mn> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced></math><texmath>\big (\varepsilon ^*_{t})^n = \varepsilon _{\theta }(({\mathbf {z}^{*}_{t}})^{n},t-1,\tau _{\theta }(y)\big )</texmath></formula> and <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msup><mrow><mo>(</mo><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow> </msup><mo>=</mo><msub><mi>&#x3B5;</mi> <mi>&#x3B8;</mi> </msub><mfenced separators='' open='(' close=')'><msup><mrow><mo>(</mo><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow> </msup> <mo>,</mo> <mi>t</mi> <mo>-</mo> <mn>1</mn> <mo>,</mo> <msub><mi>&#x3C4;</mi> <mi>&#x3B8;</mi> </msub> <mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow></mfenced></mrow></math><texmath>(\varepsilon ^*_{t})^{n-1} = \varepsilon _{\theta }\big (({\mathbf {z}^{*}_{t}})^{n-1},t-1,\tau _{\theta }(y)\big )</texmath></formula>. They finally reach:</p>
<formula id-text='11' id='uid16' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msup><mrow><mo>(</mo><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow> </msup><mo>=</mo><mi>g</mi><mrow><mo>(</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>&#xB7;</mo><msup><mrow><mo>(</mo><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mi>n</mi> </msup><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>&#xB7;</mo><msup><mrow><mo>(</mo><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow> </msup><mo>)</mo></mrow><mo>,</mo></mrow></math><texmath>
({\mathbf {z}^{*}_{t}})^{n+1} = g(0.5 \cdot (\varepsilon ^*_{t})^n+0.5 \cdot (\varepsilon ^*_{t})^{n-1}),
</texmath></formula>
<p noindent='true'>where the term <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mn>0</mn><mo>.</mo><mn>5</mn><mo>&#xB7;</mo><msup><mrow><mo>(</mo><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mi>n</mi> </msup><mo>+</mo><mn>0</mn><mo>.</mo><mn>5</mn><mo>&#xB7;</mo><msup><mrow><mo>(</mo><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>)</mo></mrow> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow> </msup></mrow></math><texmath>0.5 \cdot (\varepsilon ^*_{t})^n+0.5 \cdot (\varepsilon ^*_{t})^{n-1}</texmath></formula> represents the refinement technique for <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon ^*_{t}</texmath></formula> as suggested by Pan <hi rend='it'>et al.</hi>. If we were to apply the function <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>d</mi></math><texmath>d</texmath></formula> to both sides of Eq. (<ref target='uid16'/>), it would align perfectly with the form of Eq. (<ref target='uid15'/>). Their experiments have demonstrated that this approach is more effective than both Anderson's method  <cit><ref target='bid16'/></cit> and other techniques in inversion tasks.</p>
<p>Despite the progress made, this paper acknowledges inherent limitations in the practical implementation of the inversion technique:
(1) Inversion Efficiency: While the method outlined in Eq. (<ref target='uid16'/>) has shown improvements over traditional fixed-point iteration, it still relies on iterative optimization. The need for multiple forward passes through the diffusion model is computationally demanding and can result in inefficiencies in downstream applications.
(2) Inversion Performance: The theoretical improvements presented assume that <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>=</mo><msub><mi>&#x3B5;</mi> <mi>t</mi> </msub></mrow></math><texmath>\varepsilon ^*_t = \varepsilon _t</texmath></formula>. However, iterative optimization does not guarantee the exact fulfillment of Equation (<ref target='uid12'/>) for every time step <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>t</mi></math><texmath> t </texmath></formula>. Therefore, while the method may theoretically offer superior performance, cumulative errors can sometimes lead to practical outcomes that are less satisfactory than those achieved with the standard DDIM Inversion method, as shown in Figure <ref target='uid1'/>.</p>
</div1>
<div1 id-text='3.3' id='uid17'><head>EasyInv</head>
<p>To facilitate our subsequent analysis, we introduce the notation <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>t</mi> </msub></math><texmath>\bar{\alpha }_{t}</texmath></formula> to represent <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msqrt><mfrac><msub><mi>&#x3B1;</mi> <mi>t</mi> </msub> <msub><mi>&#x3B1;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub></mfrac></msqrt></math><texmath>\sqrt{\frac{\alpha _{t}}{\alpha _{t-1}}}</texmath></formula> and <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mover accent='true'><mi>&#x3B2;</mi> <mo>&#xAF;</mo></mover> <mi>t</mi> </msub></math><texmath>\bar{\beta }_{t}</texmath></formula> to denote <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msqrt><mfrac><msub><mi>&#x3B1;</mi> <mi>t</mi> </msub> <msub><mi>&#x3B1;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub></mfrac></msqrt><mfenced separators='' open='(' close=')'><msqrt><mrow><mfrac><mn>1</mn> <msub><mi>&#x3B1;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub></mfrac><mo>-</mo><mn>1</mn></mrow></msqrt> <mo>-</mo> <msqrt><mrow><mfrac><mn>1</mn> <msub><mi>&#x3B1;</mi> <mi>t</mi> </msub></mfrac><mo>-</mo><mn>1</mn></mrow></msqrt></mfenced></mrow></math><texmath>\sqrt{\frac{\alpha _{t}}{\alpha _{t-1}}}\Big (\sqrt{\frac{1}{\alpha _{t-1}} - 1} - \sqrt{\frac{1}{\alpha _t} - 1} \Big )</texmath></formula>. With these notations, we can reframe Eq. (<ref target='uid7'/>) as follow:</p>
<formula id-text='12' id='uid18' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>=</mo><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>t</mi> </msub><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup><mo>+</mo><msub><mover accent='true'><mi>&#x3B2;</mi> <mo>&#xAF;</mo></mover> <mi>t</mi> </msub><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>,</mo></mrow></math><texmath>
\mathbf {z}^*_{t}=\bar{\alpha }_{t}\mathbf {z}^*_{t-1} + \bar{\beta }_{t}\varepsilon ^*_{t},
</texmath></formula>
<p>Similarly, we can express the form of <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{t-1}</texmath></formula> as:</p>
<formula id-text='13' id='uid19' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup><mo>=</mo><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow> <mo>*</mo> </msubsup><mo>+</mo><msub><mover accent='true'><mi>&#x3B2;</mi> <mo>&#xAF;</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub><msubsup><mi>&#x3B5;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup><mo>,</mo></mrow></math><texmath>
\mathbf {z}^*_{t-1}=\bar{\alpha }_{t-1}\mathbf {z}^*_{t-2} + \bar{\beta }_{t-1}\varepsilon ^*_{t-1},
</texmath></formula>
<p>By combining these two formulas, we derive:</p>
<formula id-text='14' id='uid20' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>=</mo><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>t</mi> </msub><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub><msubsup><mi>&#x1D433;</mi> <mrow><mi>t</mi><mo>-</mo><mn>2</mn></mrow> <mo>*</mo> </msubsup><mo>+</mo><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>t</mi> </msub><msub><mover accent='true'><mi>&#x3B2;</mi> <mo>&#xAF;</mo></mover> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> </msub><msubsup><mi>&#x3B5;</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup><mo>+</mo><msub><mover accent='true'><mi>&#x3B2;</mi> <mo>&#xAF;</mo></mover> <mi>t</mi> </msub><msubsup><mi>&#x3B5;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>.</mo></mrow></math><texmath>
\mathbf {z}^*_{t}=\bar{\alpha }_{t}\bar{\alpha }_{t-1}\mathbf {z}^*_{t-2} + \bar{\alpha }_{t}\bar{\beta }_{t-1}\varepsilon ^*_{t-1} + \bar{\beta }_{t}\varepsilon ^*_{t}.
</texmath></formula>
<p>This can be further generalized to:</p>
<formula id-text='15' id='uid21' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup><mo>=</mo><mrow><mo>(</mo><munderover><mo>&#x0220F;</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>t</mi> </munderover><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>i</mi> </msub><mo>)</mo></mrow><msubsup><mi>&#x1D433;</mi> <mn>0</mn> <mo>*</mo> </msubsup><mo>+</mo><munderover><mo>&#x02211;</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>t</mi> </munderover><mrow><mo>(</mo><msub><mover accent='true'><mi>&#x3B2;</mi> <mo>&#xAF;</mo></mover> <mi>i</mi> </msub><munderover><mo>&#x0220F;</mo> <mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow> <mi>t</mi> </munderover><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>j</mi> </msub><mo>)</mo></mrow><msubsup><mi>&#x3B5;</mi> <mi>i</mi> <mo>*</mo> </msubsup><mo>.</mo></mrow></math><texmath>
\mathbf {z}^*_{t} = (\prod _{i=1}^{t}\bar{\alpha }_i)\mathbf {z}^*_{0} + \sum _{i=1}^{t}(\bar{\beta }_i\prod _{j = i+1}^{t}\bar{\alpha }_j)\varepsilon ^*_i.
</texmath></formula>
<p>From Eq. (<ref target='uid21'/>), it is evident that <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{t}</texmath></formula> is a weighted sum of <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mn>0</mn> </msub></math><texmath>\mathbf {z}_{0}</texmath></formula> and a series of noise terms <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>i</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon ^*_i</texmath></formula>. The denoising process of Eq. (<ref target='uid5'/>) aims to iteratively reduce the impact of these noise terms. In prior research, the crux of inversion is to introduce the appropriate noise <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>i</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon ^*_i</texmath></formula> at each step to identify a suitable <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mi>t</mi> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{t}</texmath></formula>. This allows the model to obtain <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mn>0</mn> </msub></math><texmath>\mathbf {z}_{0}</texmath></formula> as the final output after the denoising process. However, iteratively updating <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x3B5;</mi> <mi>i</mi> <mo>*</mo> </msubsup></math><texmath>\varepsilon ^*_i</texmath></formula> can be time-consuming, and when the model lacks high precision, achieving satisfactory results within a reasonable number of iterations may be challenging.</p>
<p>To address this, we propose an alternative perspective. During inversion, rather than searching for better noise, we aggregate the latent state from the last time step <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mrow><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{\bar{t}-1}</texmath></formula> with the current latent state <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{\bar{t}}</texmath></formula> at specific time steps <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover></math><texmath>\bar{t}</texmath></formula>, as illustrated in the following formula:</p>
<formula id-text='16' id='uid22' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mrow><msubsup><mi>&#x1D433;</mi> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> <mo>*</mo> </msubsup><mo>=</mo><mi>&#x3B7;</mi><msubsup><mi>&#x1D433;</mi> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> <mo>*</mo> </msubsup><mo>+</mo><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>&#x3B7;</mi><mo>)</mo></mrow><msubsup><mi>&#x1D433;</mi> <mrow><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup><mo>,</mo></mrow></math><texmath>
\mathbf {z}^*_{\bar{t}}=\eta \mathbf {z}^*_{\bar{t}} + (1-\eta ) \mathbf {z}^*_{{\bar{t}-1}},
</texmath></formula>
<p noindent='true'>where <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mi>&#x3B7;</mi></math><texmath>\eta </texmath></formula> is a trade-off parameter, typically set to <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>&#x3B7;</mi><mo>&#x2265;</mo><mn>0</mn><mo>.</mo><mn>7</mn></mrow></math><texmath>\eta \ge 0.7</texmath></formula>. The selection of <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover></math><texmath>\bar{t}</texmath></formula> will be discussed in Sec. <ref target='uid28'/>. This approach effectively increases the weight <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mn>0</mn> </msub></math><texmath>\mathbf {z}_{0}</texmath></formula> in <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{\bar{t}}</texmath></formula>, since:</p>
<formula id-text='17' id='uid23' textype='equation' type='display'><math mode='display' xmlns='http://www.w3.org/1998/Math/MathML'><mtable displaystyle='true'><mtr><mtd columnalign='right'><mrow><msubsup><mi>&#x1D433;</mi> <mrow><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup><mo>-</mo><msubsup><mi>&#x1D433;</mi> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> <mo>*</mo> </msubsup><mo>=</mo><mrow><mo>(</mo><munderover><mo>&#x0220F;</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>-</mo><mn>1</mn></mrow> </munderover><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>i</mi> </msub><mo>)</mo></mrow><mrow><mo>(</mo><mn>1</mn><mo>-</mo><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> </msub><mo>)</mo></mrow><msub><mi>&#x1D433;</mi> <mn>0</mn> </msub></mrow></mtd></mtr><mtr><mtd columnalign='right'><mrow><mo>+</mo><mrow><mo>(</mo><mn>1</mn><mo>-</mo><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> </msub><mo>)</mo></mrow><munderover><mo>&#x02211;</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mrow><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>-</mo><mn>1</mn></mrow> </munderover><mrow><mo>(</mo><msub><mover accent='true'><mi>&#x3B2;</mi> <mo>&#xAF;</mo></mover> <mi>i</mi> </msub><munderover><mo>&#x0220F;</mo> <mrow><mi>j</mi><mo>=</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow> <mrow><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>-</mo><mn>1</mn></mrow> </munderover><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>j</mi> </msub><mo>)</mo></mrow><msubsup><mi>&#x3B5;</mi> <mi>i</mi> <mo>*</mo> </msubsup><mo>+</mo><mrow><mo>(</mo><mo>-</mo><msub><mover accent='true'><mi>&#x3B2;</mi> <mo>&#xAF;</mo></mover> <mi>t</mi> </msub><mo>)</mo></mrow><msubsup><mi>&#x3B5;</mi> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> <mo>*</mo> </msubsup></mrow></mtd></mtr></mtable></math><texmath>
\begin{split}
\mathbf {z}^*_{{\bar{t}-1}} - \mathbf {z}^*_{\bar{t}} = (\prod _{i=1}^{\bar{t}-1}\bar{\alpha }_i)(1 - \bar{\alpha }_{\bar{t}})\mathbf {z}_{0} \\+ (1 - \bar{\alpha }_{\bar{t}})\sum _{i=1}^{\bar{t}-1}(\bar{\beta }_i\prod _{j = i+1}^{\bar{t}-1}\bar{\alpha }_j)\varepsilon ^*_i + (-\bar{\beta }_{t})\varepsilon ^*_{\bar{t}}
\end{split}
</texmath></formula>
<p>Given that <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mn>0</mn><mo>&lt;</mo><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>i</mi> </msub><mo>&lt;</mo><mn>1</mn></mrow></math><texmath>0 &lt; \bar{\alpha }_i &lt; 1</texmath></formula>, for <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>i</mi><mo>=</mo><mn>0</mn><mo>&#x02192;</mo><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover></mrow></math><texmath> i = 0 \rightarrow \bar{t}</texmath></formula>, it follows that <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mrow><mo>(</mo><msubsup><mo>&#x0220F;</mo> <mrow><mi>i</mi><mo>=</mo><mn>0</mn></mrow> <mrow><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>-</mo><mn>1</mn></mrow> </msubsup><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mi>i</mi> </msub><mo>)</mo></mrow><mrow><mo>(</mo><mn>1</mn><mo>-</mo><msub><mover accent='true'><mi>&#x3B1;</mi> <mo>&#xAF;</mo></mover> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> </msub><mo>)</mo></mrow><mo>&gt;</mo><mn>0</mn></mrow></math><texmath>(\prod _{i=0}^{\bar{t}-1}\bar{\alpha }_i)(1 - \bar{\alpha }_{\bar{t}}) &gt; 0</texmath></formula>. Consequently, in comparison to <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{\bar{t}}</texmath></formula>, <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mrow><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>-</mo><mn>1</mn></mrow> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{\bar{t}-1}</texmath></formula> carries a higher proportion of <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mn>0</mn> </msub></math><texmath>\mathbf {z}_0</texmath></formula> and is, therefore, less susceptible to the influence of noise. Our approach, therefore, accentuates the significance of the initial latent state <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msub><mi>&#x1D433;</mi> <mn>0</mn> </msub></math><texmath>\mathbf {z}_0</texmath></formula>, which encapsulates the most comprehensive information regarding the original image, within <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><msubsup><mi>&#x1D433;</mi> <mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover> <mo>*</mo> </msubsup></math><texmath>\mathbf {z}^*_{\bar{t}}</texmath></formula>.</p>
<table rend='display' id-text='1' id='uid24' starred='true' place='!t'><head>A comparative analysis of quantitative outcomes utilizing the SD-V1-4 model.</head>
<row spaceafter='2.125pt'><cell halign='center'/>
<cell halign='center'>LPIPS (<formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mo>&#x02193;</mo></math><texmath>\downarrow </texmath></formula>)</cell>
<cell halign='center'>SSIM (<formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mo>&#x02191;</mo></math><texmath>\uparrow </texmath></formula>)</cell>
<cell halign='center'>PSNR (<formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mo>&#x02191;</mo></math><texmath>\uparrow </texmath></formula>)</cell>
<cell halign='center'>Time (<formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mo>&#x02193;</mo></math><texmath>\downarrow </texmath></formula>)</cell>
</row><row bottom-border='true'><cell halign='center'>DDIM Inversion</cell>
<cell halign='center'>0.328</cell>
<cell halign='center'>0.621</cell>
<cell halign='center'>29.717</cell>
<cell halign='center'><hi rend='bold'>5s</hi></cell>
</row><row bottom-border='true'><cell halign='center'>ReNoise</cell>
<cell halign='center'><hi rend='bold'>0.316</hi></cell>
<cell halign='center'>0.641</cell>
<cell halign='center'><hi rend='bold'>31.025</hi></cell>
<cell halign='center'>16s</cell>
</row><row bottom-border='true'><cell halign='center'>Fixed-Point Iteration</cell>
<cell halign='center'>0.373</cell>
<cell halign='center'>0.563</cell>
<cell halign='center'>29.107</cell>
<cell halign='center'>14s</cell>
</row><row><cell halign='center'>EasyInv (Ours)</cell>
<cell halign='center'>0.321</cell>
<cell halign='center'><hi rend='bold'>0.646</hi></cell>
<cell halign='center'>30.189</cell>
<cell halign='center'><hi rend='bold'>5s</hi></cell>
</row></table>
<table rend='display' id-text='2' id='uid25' starred='true' place='!tb'><head>A comparative analysis of half- and full-precision EasyInv utilizing the SD-V1-4.</head>
<row spaceafter='2.125pt'><cell halign='center'/>
<cell halign='center'>LPIPS (<formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mo>&#x02193;</mo></math><texmath>\downarrow </texmath></formula>)</cell>
<cell halign='center'>SSIM (<formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mo>&#x02191;</mo></math><texmath>\uparrow </texmath></formula>)</cell>
<cell halign='center'>PSNR (<formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mo>&#x02191;</mo></math><texmath>\uparrow </texmath></formula>)</cell>
<cell halign='center'>Time (<formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mo>&#x02193;</mo></math><texmath>\downarrow </texmath></formula>)</cell>
</row><row bottom-border='true'><cell halign='center'>Full Precision</cell>
<cell halign='center'>0.321</cell>
<cell halign='center'>0.646</cell>
<cell halign='center'>30.184</cell>
<cell halign='center'>9s</cell>
</row><row><cell halign='center'>Half Precision</cell>
<cell halign='center'>0.321</cell>
<cell halign='center'>0.646</cell>
<cell halign='center'><hi rend='bold'>30.189</hi></cell>
<cell halign='center'><hi rend='bold'>5s</hi></cell>
</row></table>
</div1></div0>
<div0 id-text='4' id='cid4'><head>Experimentation</head>
<p>We compare our EasyInv over the vanilla DDIM Inversion  <cit><ref target='bid5'/></cit>, ReNoise <cit><ref target='bid9'/></cit>, Pan <hi rend='it'>et al.</hi>'s method <cit><ref target='bid8'/></cit> (referred to as Fixed-Point Iteration), using SD V1.4 and SD-XL on one NVIDIA GTX 3090 GPU.</p>
<p>For Fixed-Point Iteration <cit><ref target='bid8'/></cit>, we re-implemented it using settings from the paper, as the source code is unavailable. We set the data type of all methods to float16 by default to improve efficiency. The inversion and denoising steps <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>T</mi><mo>=</mo><mn>50</mn></mrow></math><texmath>T = 50</texmath></formula>, except for Fixed-Point Iteration, which recommends <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>T</mi><mo>=</mo><mn>20</mn></mrow></math><texmath>T = 20</texmath></formula>. For our EasyInv, we use <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mn>0</mn><mo>.</mo><mn>85</mn><mo>&#xB7;</mo><mi>T</mi><mo>&lt;</mo><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>&lt;</mo><mn>0</mn><mo>.</mo><mn>95</mn><mo>&#xB7;</mo><mi>T</mi></mrow></math><texmath>0.85 \cdot T &lt; \bar{t} &lt; 0.95 \cdot T</texmath></formula> and <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>&#x3B7;</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>8</mn></mrow></math><texmath>\eta = 0.8</texmath></formula> with the SD-XL framework, and <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mn>0</mn><mo>.</mo><mn>05</mn><mo>&#xB7;</mo><mi>T</mi><mo>&lt;</mo><mover accent='true'><mi>t</mi> <mo>&#xAF;</mo></mover><mo>&lt;</mo><mn>0</mn><mo>.</mo><mn>25</mn><mo>&#xB7;</mo><mi>T</mi></mrow></math><texmath>0.05 \cdot T &lt; \bar{t} &lt; 0.25 \cdot T</texmath></formula> and <formula type='inline'><math xmlns='http://www.w3.org/1998/Math/MathML'><mrow><mi>&#x3B7;</mi><mo>=</mo><mn>0</mn><mo>.</mo><mn>5</mn></mrow></math><texmath>\eta = 0.5</texmath></formula> with SD-V1-4, due to the varying capacities of the two models.</p>
<p>For quantitative comparison, we use three major metrics: LPIPS index <cit><ref target='bid18'/></cit>, SSIM <cit><ref target='bid19'/></cit>, and PSNR. The LPIPS index uses a pre-trained VGG16 <cit><ref target='bid20'/></cit> to compare image pairs. SSIM and PSNR measure image similarity. We also report inference time. We randomly sample 2,298 images from the COCO 2017 test and validation sets <cit><ref target='bid21'/></cit>. With the well-trained SD-XL model, error accumulation is minimal, making all methods perform similarly. Therefore, we display results using the SD-V1-4 model.</p>
<figure width='418.45818pt' file='visual_SDXL' extension='pdf' id-text='3' id='uid26' place='!t'><head>A visual assessment of various inversion techniques utilizing the SD-XL model.</head>
</figure>
<figure width='418.45818pt' file='visual_SDV1-4' extension='pdf' id-text='4' id='uid27' place='!t'><head>A visual assessment of various inversion techniques utilizing the SD-V1-4 model.</head>
</figure>
<div1 id-text='4.1' id='uid28'><head>Quantitative Results</head>
<p>Table <ref target='uid24'/> presents the quantitative results of different methods. EasyInv achieves a competitive LPIPS score of 0.321, better than ReNoise (0.316) and Fixed-Point Iteration (0.373), indicating closer perceptual similarity to the original image. For SSIM, EasyInv achieves the highest score of 0.646, showing superior structural similarity crucial for maintaining image coherence. For PSNR, EasyInv scores 30.189, close to ReNoise's highest score of 31.025, indicating high image fidelity. EasyInv completes the inversion process in the fastest time of 5 seconds, matching DDIM Inversion, and significantly quicker than ReNoise (16 seconds) and Fixed-Point Iteration (14 seconds), highlighting its efficiency without compromising on quality. In summary, EasyInv performs strongly across all metrics, with the highest SSIM score indicating effective preservation of image structure. Its efficient inversion makes it highly suitable for real-world applications where both quality and speed are crucial.</p>
<p>Table <ref target='uid25'/> compares EasyInv's performance in half-precision (float16) and full-precision (float32) formats. Both achieve the same LPIPS score of 0.321, indicating consistent perceptual similarity to the original image. Similarly, both achieve an SSIM score of 0.646, showing preserved structural integrity with high fidelity. For PSNR, half precision slightly outperforms full precision with scores of 30.189 and 30.184. This slight advantage in PSNR for half precision is noteworthy given its well reduced computation time. The most significant difference is observed in the time metric, where half precision completes the inversion process in 5 seconds, approximately 44% faster than full precision, which takes 9 seconds. This efficiency gain highlights EasyInv's exceptional optimization for half precision, offering faster speeds and reduced resources without compromising output quality.</p>
<figure rend='array' id-text='5' id='uid29' starred='true'><head>More visual results of our EasyInv utilizing the SD-V1-4 model.</head>
<p><table rend='inline'><row><cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='original_compare/2' extension='pdf'/>
</p></minipage></cell>
<cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='Ours_compare/2' extension='pdf'/>
</p></minipage></cell>
<cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='original_compare/20' extension='pdf'/>
</p></minipage></cell>
<cell><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='Ours_compare/20' extension='pdf'/>
</p></minipage></cell>
</row><row><cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='original_compare/24' extension='pdf'/>
</p></minipage></cell>
<cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='Ours_compare/24' extension='pdf'/>
</p></minipage></cell>
<cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='original_compare/26' extension='pdf'/>
</p></minipage></cell>
<cell><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='Ours_compare/26' extension='pdf'/>
</p></minipage></cell>
</row><row><cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='original_compare/58' extension='pdf'/>
</p></minipage></cell>
<cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='Ours_compare/58' extension='pdf'/>
</p></minipage></cell>
<cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='original_compare/65' extension='pdf'/>
</p></minipage></cell>
<cell><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='Ours_compare/65' extension='pdf'/>
</p></minipage></cell>
</row><row><cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='original_compare/90' extension='pdf'/>
*figureOriginal image
</p></minipage></cell>
<cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='Ours_compare/90' extension='pdf'/>
*figureEasyInv (Ours)
</p></minipage></cell>
<cell halign='center'><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='original_compare/1709' extension='pdf'/>
*figureOriginal image
</p></minipage></cell>
<cell><minipage width='427.0pt'><p><figure rend='inline' width='427.0pt' file='Ours_compare/1709' extension='pdf'/>
*figureEasyInv (Ours)
</p></minipage></cell>
</row></table></p></figure>
</div1>
<div1 id-text='4.2' id='uid30'><head>Qualitative Results</head>
<p>We visually evaluate all methods using SD-XL and SD-V1-4. Figure <ref target='uid26'/> presents a comparison of several examples across all methods utilizing SD-XL. ReNoise struggles with images containing significant white areas, resulting in black images. The other two methods also perform poorly, especially evident in the clock example.
Figure <ref target='uid27'/> displays the results obtained from the SD-V1-4 using images sourced from the internet. These images also feature large areas of white color. ReNoise consistently produces black images with these inputs, indicating an issue inherent to the method rather than the model. Fixed-Point Iteration and DDIM Inversion also fail to generate satisfactory results in such cases, suggesting these images pose challenges for inversion methods. Our method, shown in the figure, effectively addresses these challenges, demonstrating robustness and enhancing performance in handling special scenarios.
These findings underscore the efficacy of our approach, particularly in addressing challenging cases that are less common in the COCO dataset.</p>
<p>Figure <ref target='uid29'/> presents more visual results of our method, with original images exclusively obtained from the COCO dataset <cit><ref target='bid21'/></cit>. The results are unequivocal: our approach consistently generates images that closely resemble their originals post-inversion and reconstruction. The variety of categories represented in these images underscores the broad applicability and consistent performance of our method. In aggregate, these findings affirm that our technique is not merely efficient but also remarkably robust, adeptly reconstructing images with a high level of precision and clarity.</p>
<figure width='418.45818pt' file='visual_masa_cut' extension='pdf' id-text='6' id='uid31' place='!t'><head>Results of MasaCtrl <cit><ref target='bid6'/></cit> with prompt “A football”, using inverted latent generated by different methods as input.</head>
</figure>
</div1>
<div1 id-text='4.3' id='uid32'><head>Downstream Image Editing</head>
<p>To showcase the practical utility of our EasyInv, we have employed various inversion techniques within the realm of consistent image synthesis and editing. We have seamlessly integrated these inversion methods into MasaCtrl <cit><ref target='bid6'/></cit>, a widely-adopted image editing approach that extracts correlated local content and textures from source images to ensure consistency. For demonstrative purposes, we present an image of a “peach” alongside the prompt “A football.” The impact of inversion quality is depicted in Figure <ref target='uid31'/>. In these instances, we utilize the inverted latents of the “peach” image, as shown in Figure <ref target='uid27'/>, as the input for MasaCtrl <cit><ref target='bid6'/></cit>. Our ultimate goal is to generate an image of a football that retains the distinctive features of the “peach” image. As evident from Figure <ref target='uid31'/>, our EasyInv achieves superior texture quality and a shape most closely resembling that of a football. From our perspective, images with extensive white areas constitute a significant category in actual image editing, given that they are a prevalent characteristic in conventional photography. However, such features often prove detrimental to the ReNoise method. Thus, for authentic image editing scenarios, our approach stands out as a preferable alternative, not to mention its commendable efficiency.</p>
</div1>
<div1 id-text='4.4' id='uid33'><head>Limitations</head>
<p>One potential risk associated with our approach is the phenomenon known as “over-denoising,” which occurs when there is a disproportionate focus on achieving a pristine final-step latent state. This can occasionally result in overly smooth image outputs, as exemplified by the “peach” figure in Figure <ref target='uid27'/>.
In the context of most real-world image editing tasks, this is not typically an issue, as these tasks often involve style migration, which inherently alters the details of the original image. However, in specific applications, such as using diffusion models for creating advertisements, this could pose a challenge.
Nonetheless, our experimental results highlight that the method's two key benefits significantly outweigh this minor shortcoming. Firstly, it is capable of delivering satisfactory outcomes even with models that may under-perform relative to other methods, as shown in the above experiments. Secondly, it enhances inversion efficiency by reverting to the original DDIM Inversion baseline <cit><ref target='bid5'/></cit>, thereby eliminating the necessity for iterative optimizations. This strategy not only simplifies the process but also ensures the maintenance of high-quality outputs, marking it as a noteworthy advancement over current methodologies.</p>
<p>In conclusion, our research has made significant strides with the introduction of EasyInv. As we look ahead, our commitment to advancing this technology remains unwavering. Our future research agenda will be focused on the persistent enhancement and optimization of the techniques in this paper. This will be done with the ultimate goal of ensuring that our methodology is not only robust and efficient but also highly adaptable to the diverse and ever-evolving needs of industrial applications.</p>
</div1></div0>
<div0 id-text='5' id='cid5'><head>Conclusion</head>
<p>Our EasyInv presents a significant advancement in the field of DDIM Inversion by addressing the inefficiencies and performance limitations in traditional iterative optimization methods. By emphasizing the importance of the initial latent state and introducing a refined strategy for approximating inversion noise, EasyInv enhances both the accuracy efficiency of the inversion process. Our method strategically reinforces the initial latent state's influence, mitigating the impact of noise and ensuring a closer reconstruction to the original image. This approach not only matches but often surpasses the performance of existing DDIM Inversion methods, especially in scenarios with limited model precision or computational resources. EasyInv also demonstrates a remarkable improvement in inference efficiency, achieving approximately three times faster processing than standard iterative techniques. Through extensive evaluations, we have shown that EasyInv consistently delivers high-quality results, making it a robust and efficient solution for image inversion tasks. The simplicity and effectiveness of EasyInv underscore its potential for broader applications, promoting greater accessibility and advancement in the field of diffusion models.</p>
<Bibliography><p noindent='true'><bibitem id='bid16'/>Anderson, D. G. 1965.
Iterative procedures for nonlinear integral equations.
<hi rend='it'>Journal of the ACM</hi>.</p>
<p noindent='true'><bibitem id='bid17'/>Bauschke, H. H.; Burachik, R. S.; Combettes, P. L.; Elser, V.; Luke, D. R.; and Wolkowicz, H. 2011.
<hi rend='it'>Fixed-point algorithms for inverse problems in science and engineering</hi>, volume 49.
Springer Science &amp; Business Media.</p>
<p noindent='true'><bibitem id='bid1'/>Betker, J.; Goh, G.; Jing, L.; Brooks, T.; Wang, J.; Li, L.; Ouyang, L.; Zhuang, J.; Lee, J.; Guo, Y.; et al. 2023.
Improving image generation with better captions.
<hi rend='it'>Computer Science</hi>.</p>
<p noindent='true'><bibitem id='bid6'/>Cao, M.; Wang, X.; Qi, Z.; Shan, Y.; Qie, X.; and Zheng, Y. 2023.
MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing.
In <hi rend='it'>International Conference on Computer Vision</hi>.</p>
<p noindent='true'><bibitem id='bid5'/>Couairon, G.; Verbeek, J.; Schwenk, H.; and Cord, M. 2023.
DiffEdit: Diffusion-based Semantic Image Editing with Mask Guidance.
In <hi rend='it'>International Conference on Learning Representations</hi>.</p>
<p noindent='true'><bibitem id='bid12'/>Dong, W.; Xue, S.; Duan, X.; and Han, S. 2023.
Prompt tuning inversion for text-driven image editing using diffusion models.
In <hi rend='it'>International Conference on Computer Vision</hi>.</p>
<p noindent='true'><bibitem id='bid9'/>Garibi, D.; Patashnik, O.; Voynov, A.; Averbuch-Elor, H.; and Cohen-Or, D. 2024.
ReNoise: Real Image Inversion Through Iterative Noising.
<hi rend='it'>arXiv preprint arXiv:2403.14602</hi>.</p>
<p noindent='true'><bibitem id='bid4'/>Hertz, A.; Mokady, R.; Tenenbaum, J.; Aberman, K.; Pritch, Y.; and Cohen-or, D. 2022.
Prompt-to-Prompt Image Editing with Cross-Attention Control.
In <hi rend='it'>International Conference on Learning Representations</hi>.</p>
<p noindent='true'><bibitem id='bid14'/>Ho, J.; Jain, A.; and Abbeel, P. 2020.
Denoising diffusion probabilistic models.
<hi rend='it'>Advances in neural information processing systems</hi>.</p>
<p noindent='true'><bibitem id='bid11'/>Ju, X.; Zeng, A.; Bian, Y.; Liu, S.; and Xu, Q. 2023.
Direct Inversion: Boosting Diffusion-based Editing with 3 Lines of Code.
In <hi rend='it'>International Conference on Learning Representations</hi>.</p>
<p noindent='true'><bibitem id='bid21'/>Lin, T.-Y.; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Dollár, P.; and Zitnick, C. L. 2014.
Microsoft COCO: Common Objects in Context.
In <hi rend='it'>European Conference on Computer Vision</hi>.</p>
<p noindent='true'><bibitem id='bid7'/>Liu, J.; Huang, H.; Jin, C.; and He, R. 2023.
Portrait Diffusion: Training-free Face Stylization with Chain-of-Painting.
<hi rend='it'>arXiv preprint arXiv:2312.02212</hi>.</p>
<p noindent='true'><bibitem id='bid10'/>Mokady, R.; Hertz, A.; Aberman, K.; Pritch, Y.; and Cohen-Or, D. 2023.
Null-text inversion for editing real images using guided diffusion models.
In <hi rend='it'>Computer Vision and Pattern Recognition</hi>.</p>
<p noindent='true'><bibitem id='bid2'/>Openai. 2024.
ChatGPT.
<xref url='https://chat.openai.com/'>https://<allowbreak/>chat.<allowbreak/>openai.<allowbreak/>com/<allowbreak/></xref>, Last accessed on 2024-2-27.</p>
<p noindent='true'><bibitem id='bid8'/>Pan, Z.; Gherardi, R.; Xie, X.; and Huang, S. 2023.
Effective Real Image Editing with Accelerated Iterative Diffusion Inversion.
In <hi rend='it'>International Conference on Computer Vision</hi>.</p>
<p noindent='true'><bibitem id='bid13'/>Podell, D.; English, Z.; Lacey, K.; Blattmann, A.; Dockhorn, T.; Müller, J.; Penna, J.; and Rombach, R. 2023.
SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis.
In <hi rend='it'>International Conference on Learning Representations</hi>.</p>
<p noindent='true'><bibitem id='bid0'/>Rombach, R.; Blattmann, A.; Lorenz, D.; Esser, P.; and Ommer, B. 2022.
High-resolution image synthesis with latent diffusion models.
In <hi rend='it'>Computer Vision and Pattern Recognition</hi>.</p>
<p noindent='true'><bibitem id='bid20'/>Simonyan, K.; and Zisserman, A. 2015.
Very deep convolutional networks for large-scale image recognition.
In <hi rend='it'>International Conference on Learning Representations</hi>.</p>
<p noindent='true'><bibitem id='bid15'/>Song, J.; Meng, C.; and Ermon, S. 2020.
Denoising Diffusion Implicit Models.
In <hi rend='it'>International Conference on Learning Representations</hi>.</p>
<p noindent='true'><bibitem id='bid19'/>Wang, Z.; Bovik, A. C.; Sheikh, H. R.; and Simoncelli, E. P. 2004.
Image quality assessment: from error visibility to structural similarity.
<hi rend='it'>IEEE transactions on image processing</hi>.</p>
<p noindent='true'><bibitem id='bid18'/>Zhang, R.; Isola, P.; Efros, A. A.; Shechtman, E.; and Wang, O. 2018.
The unreasonable effectiveness of deep features as a perceptual metric.
In <hi rend='it'>Computer Vision and Pattern Recognition</hi>.</p>
<p noindent='true'><bibitem id='bid3'/>Zhang, Z.; Lin, M.; and Ji, R. 2024.
ObjectAdd: Adding Objects into Image via a Training-Free Diffusion Modification Fashion.
<hi rend='it'>arXiv preprint arXiv:2404.17230</hi>.</p>
</Bibliography></div0></std>
