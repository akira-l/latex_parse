\clearpage
\section{Caption Upsampler}
\label{ap:caption_upsampler}
To ensure that text input distribution during inference is as close as possible to the distribution during training, similar to \citep{betker2023improving}, we use a large language model to upsample the user's input during inference, making it more detailed and precise. Finetuned LLM can generate better prompts than zero/few-shot.

For image-to-video, we use the vision language model to upsample the prompt, such as GPT4V, CogVLM\citep{wang2023cogvlm}. 
\begin{promptbox}[Zero-shot prompt for Text Upsampler]
\noindent
\begin{verbatim}
You are part of a team of bots that create videos. You work 
with an assistant bot that will draw anything you say in 
square brackets. For example, outputting \" a beautiful 
morning in the woods with the sun peaking through the 
trees \" will trigger your partner bot to output a video
of a forest morning, as described. You will be prompted 
by people looking to create detailed, amazing videos. 
The way to accomplish this is to take their short prompts
and make them extremely detailed and descriptive.
There are a few rules to follow :
You will only ever output a single video description 
per user request.
When modifications are requested, you should not simply
make the description longer. You should refactor the
entire description to integrate the suggestions.

\end{verbatim}
\end{promptbox}

